# Chapter1 OLS
[TOC]

## 1.1.A 线性回归: OLS
### 1.1.1 一元回归模型
我们知道, 计量经济学的目标之一是实现因果推断, 当然, 我们首先要讨论“何为因果关系”. 在数学上, 具有严格定义的首先是**相关性**, 这一概念用相关系数即可刻画, 也只有相关的变量我们才有可能去讨论因果; 而对于**因果关系**, 经济学中的定义是: 控制其他因素不变, 解释变量变动会引起被解释变量的变动, 我们称这种关系为因果关系.

在这一节中, 我们首先讨论相关性, 引入一元回归模型.


### 1.1.2 多元回归模型
#### 1.1.2.1 多元回归模型的引入
上一节中, 我们讨论了相关性, 但经济学并不止满足于相关性, 我们更想知道因果关系, 这需要我们控制住其他因素——由于经济学得到的大部分是调查数据,没法像对比实验一样直接控制变量, 无论是成本上还是伦理上, 我们需要统计上的方法进行变量控制; 而一元回归模型中, 所有的其他因素都被归结到了扰动项中, 为了实现对其他因素的控制, 我们需要将原本放入扰动项中的因素同样加入到回归模型中, 因此, 引入多元回归模型.

引入多元回归模型后, 我们的模型得到了很丰富的扩展: 一方面, 我们通过引入更多的变量来增强模型的解释能力; 另一方面, 还可以通过引入二次项作为一个新的变量去估计边际效应. 例如：
(1).经典的人力资本理论模型, 这是通过多变量来增强模型的解释能力：$wage = \beta_0 +\beta_1 education +\beta_2 experience +\varepsilon$
(2).消费与收入关系的估计方程, 其中$\beta_2$刻画的是收入的边际效应的递减：$consumption = \beta_0 +\beta_1 income +\beta_2 income^2+\varepsilon$

为了简化讨论, 首先我们讨论二元的情形, 多元情形事实上只是对其的一种拓展. 以下讨论如下回归模型:$y=\beta_0+\beta_1 x_1+\beta_2 x_2+u$, 我们希望得到$x_1$与$y$的因果关系. 

#### 1.1.2.2 残差回归
这里介绍一种名为Partial Out的方法(也就是Residual Regression):

1. $x_1$对$x_2$回归, 得到$x_1=\hat{\alpha}_0+\hat{\alpha}_1x_2+\hat{r}_1$. 根据OLS的代数性质, $x_2$与$\hat{r}_1$是正交的, 也就是说, 剔除$x_2$对$x_1$的影响, $x_1$真正独立的部分的信息由$\hat{r}_1$反映.
2. $y$对$X_2$回归, 得到$y=\hat{\gamma}_0+\hat{\gamma}_1X_2+\hat{e}$, $\hat{e}$是$y$与$x_2$正交的部分, 也就是说, $\hat{e}$是$y$无法由$x_2$解释的部分.
3. $\hat{e}$对$\hat{r}_1$进行回归, 得到的$\hat{\beta}_1$就是直接进行OLS回归得到的$\hat{\beta}_1$.
   
这是非常符合直觉的一个想法, 相当于同时剔除$x_2$的影响, 那么剩下的$y$的变动可解释的部分只能是由$x_1$的变动提供的——这也就是[**FWL定理**](#FWL)的思想.

#### 1.1.2.3 缺失变量
一个很不幸的事实是, 现实中的影响因素是非常复杂的, 我们不可能穷尽所有的控制变量, 甚至有时候连那些变量是控制变量都无法确定; 另一方面, 在调查数据中, 常常存在误差问题(线下调查中, 往往被调查对象需要在很短时间内给出回答, 而被调查对象不可能对自己的经济状况熟悉到如此程度, 有可能存在记忆偏差或者数据缺失).


## 1.1.B OLS的推导与基本性质
### 1.1.1 推导OLS
Given observations $D_n=\{(\mathbf{x}_i,y_i)\}_{i=1}^n$, where $\mathbf{x}_i\in\mathbb{R}^n,y_i\in\mathbb{R},i=1,2\cdots,n$,assume that each observations is generated by 
$$y_i=\beta_1 x_{i1}+\cdots+\beta_{k}x_{ik}+\varepsilon_i$$
### 1.1.2 OLS的代数性质
### 1.1.3 Residual Regression
Partion $\bf{X}=\begin{bmatrix}\bf{X}_1&\bf{X}_2\end{bmatrix}$ and ${\beta}=\begin{pmatrix}\beta_1\\ \beta_2\end{pmatrix}$, then the regression model can be rewritten as 
$$y=X_1\beta_1+X_2\beta_2+e$$
and the OLS estimation can be written as 
$$y=X_1\hat{\beta}_1+X_2\hat{\beta}_2+\hat{e}$$

<span id="FWL"></span>

Theorem. (Frisch-Waugh-Lovell Theorem)
In the linear least squares regression of vector $y$ on two sets of varibles $X_1$ and $X_2$
### 1.1.4 拟合优度
### 1.1.5 OLS的无偏性
### 1.1.6 OLS的条件方差
### 1.1.7 Gauss-Markov Theorem
## 1.2.B OLS的渐进理论
### 1.2.1 OLS的一致性
### 1.2.2 OLS的渐进正态性
### 1.2.3 渐进方差的一致估计
